{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (run once only)\n",
    "\n",
    "### 1. Use Conda to create the environment with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/reach/francis/MMT_experiments/fork/mmt\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained model and train-args.json (run once only)\n",
    "\n",
    "Download from https://drive.google.com/drive/folders/15ji-jGE4GICLMpEwlPRXb-Dv_RYqKunH?usp=sharing using gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make the folder exp/midi_YX if it doesn't exist\n",
    "os.makedirs('exp/midi_YX/', exist_ok=True)\n",
    "\n",
    "# make the folder exp/midi_Y if it doesn't exist\n",
    "os.makedirs('exp/midi_Y/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder list\n",
      "Retrieving folder 1HjbBGXUE1HurRKgOlY0CpcvQXVvf8Hvr checkpoints\n",
      "Processing file 1BFG8yj-okko5SX30zunAGbI0L8ZaQRas best_model.pt\n",
      "Processing file 1b8x6Uq5br87VRMhuUOeAzXc171Szj-kK train-args.json\n",
      "Retrieving folder list completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Access denied with the following error:\n",
      "\n",
      " \tToo many users have viewed or downloaded this file recently. Please\n",
      "\ttry accessing the file again later. If the file you are trying to\n",
      "\taccess is particularly large or is shared with many people, it may\n",
      "\ttake up to 24 hours to be able to view or download the file. If you\n",
      "\tstill can't access a file after 24 hours, contact your domain\n",
      "\tadministrator. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1BFG8yj-okko5SX30zunAGbI0L8ZaQRas \n",
      "\n",
      "Download ended unsuccessfully\n"
     ]
    }
   ],
   "source": [
    "!gdown '15ji-jGE4GICLMpEwlPRXb-Dv_RYqKunH' --folder --output exp/midi_Y/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R exp/midi_Y/* exp/midi_YX/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "The input file should be a MIDI file with 2 tracks - track 1 being Y (melody) and track 2 being X (accompaniment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import muspy\n",
    "\n",
    "input_midi_file_path = '<INPUT_FILE_PATH>' # eg. '../input.mid'\n",
    "\n",
    "# copy to data/midi_YX/YX/YX.mid\n",
    "os.makedirs('data/midi_YX/YX', exist_ok=True)\n",
    "os.system('cp {0} data/midi_YX/YX/YX.mid'.format(input_midi_file_path))\n",
    "\n",
    "# save track 1 to data/midi_Y/Y/Y.mid\n",
    "os.makedirs('data/midi_Y/Y', exist_ok=True)\n",
    "music = muspy.read_midi(input_midi_file_path, backend='pretty_midi') \n",
    "music.tracks = [music.tracks[0]]\n",
    "muspy.write_midi('data/midi_Y/Y/Y.mid', music, backend='pretty_midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare list of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find data/midi_Y/Y -type f -name *.mid -o -name *.xml | cut -c 15- > data/midi_Y/original-names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find data/midi_YX/YX -type f -name *.mid -o -name *.xml | cut -c 17- > data/midi_YX/original-names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the folder data/midi_Y/processed/json if it doesn't exist\n",
    "os.makedirs('data/midi_Y/processed/json', exist_ok=True)\n",
    "\n",
    "# make the folder data/midi_YX/processed/json if it doesn't exist\n",
    "os.makedirs('data/midi_YX/processed/json', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     Using arguments:\n",
      "{'ignore_exceptions': False,\n",
      " 'in_dir': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/data/midi_Y/Y'),\n",
      " 'jobs': 1,\n",
      " 'names': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/data/midi_Y/original-names.txt'),\n",
      " 'out_dir': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/data/midi_Y/processed/json'),\n",
      " 'quiet': False,\n",
      " 'resolution': 12,\n",
      " 'skip_existing': False}\n",
      "INFO     Loading names...\n",
      "INFO     Iterating over names...\n",
      "100%|██████████████████████████████████████| 1/1 [00:00<00:00, 45.49it/s, Y.mid]\n",
      "INFO     Converted 1 out of 1 files.\n",
      "INFO     Saved the converted filenames to: /data2/reach/francis/MMT_experiments/fork/mmt/data/midi_Y/processed/json-names.txt\n"
     ]
    }
   ],
   "source": [
    "!python mmt/convert_lmd_full.py -n data/midi_Y/original-names.txt -i data/midi_Y/Y -o data/midi_Y/processed/json/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     Using arguments:\n",
      "{'ignore_exceptions': False,\n",
      " 'in_dir': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/data/midi_YX/YX'),\n",
      " 'jobs': 1,\n",
      " 'names': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/data/midi_YX/original-names.txt'),\n",
      " 'out_dir': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/data/midi_YX/processed/json'),\n",
      " 'quiet': False,\n",
      " 'resolution': 12,\n",
      " 'skip_existing': False}\n",
      "INFO     Loading names...\n",
      "INFO     Iterating over names...\n",
      "100%|█████████████████████████████████████| 1/1 [00:00<00:00, 65.67it/s, YX.mid]\n",
      "INFO     Converted 1 out of 1 files.\n",
      "INFO     Saved the converted filenames to: /data2/reach/francis/MMT_experiments/fork/mmt/data/midi_YX/processed/json-names.txt\n"
     ]
    }
   ],
   "source": [
    "!python mmt/convert_lmd_full.py -n data/midi_YX/original-names.txt -i data/midi_YX/YX -o data/midi_YX/processed/json/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract notes from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the folder data/midi_YX/processed/notes if it doesn't exist\n",
    "os.makedirs('data/midi_YX/processed/notes', exist_ok=True)\n",
    "\n",
    "# make the folder data/midi_Y/processed/notes if it doesn't exist\n",
    "os.makedirs('data/midi_Y/processed/notes', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     Using arguments:\n",
      "{'dataset': 'midi_Y',\n",
      " 'ignore_exceptions': False,\n",
      " 'in_dir': PosixPath('data/midi_Y/processed/json'),\n",
      " 'jobs': 1,\n",
      " 'names': PosixPath('data/midi_Y/processed/json-names.txt'),\n",
      " 'out_dir': PosixPath('data/midi_Y/processed/notes'),\n",
      " 'quiet': False}\n",
      "INFO     Saved the encoding to: data/midi_Y/processed/notes/encoding.json\n",
      "INFO     Loading names...\n",
      "INFO     Iterating over names...\n",
      "100%|█████████████████████████████████████| 1/1 [00:00<00:00, 743.01it/s, Y.mid]\n",
      "INFO     Extracted 1 out of 1 files.\n",
      "INFO     Saved the extracted filenames to: data/midi_Y/processed/names.txt\n"
     ]
    }
   ],
   "source": [
    "!python mmt/extract.py -d midi_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     Using arguments:\n",
      "{'dataset': 'midi_YX',\n",
      " 'ignore_exceptions': False,\n",
      " 'in_dir': PosixPath('data/midi_YX/processed/json'),\n",
      " 'jobs': 1,\n",
      " 'names': PosixPath('data/midi_YX/processed/json-names.txt'),\n",
      " 'out_dir': PosixPath('data/midi_YX/processed/notes'),\n",
      " 'quiet': False}\n",
      "INFO     Saved the encoding to: data/midi_YX/processed/notes/encoding.json\n",
      "INFO     Loading names...\n",
      "INFO     Iterating over names...\n",
      "100%|████████████████████████████████████| 1/1 [00:00<00:00, 495.55it/s, YX.mid]\n",
      "INFO     Extracted 1 out of 1 files.\n",
      "INFO     Saved the extracted filenames to: data/midi_YX/processed/names.txt\n"
     ]
    }
   ],
   "source": [
    "!python mmt/extract.py -d midi_YX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training/validation/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     Using arguments:\n",
      "{'dataset': 'midi_Y',\n",
      " 'names': PosixPath('data/midi_Y/processed/names.txt'),\n",
      " 'out_dir': PosixPath('data/midi_Y/processed'),\n",
      " 'quiet': False,\n",
      " 'ratio_test': 1.0,\n",
      " 'ratio_valid': 0.0,\n",
      " 'seed': 0}\n",
      "INFO     Loading names...\n",
      "INFO     Loaded 1 names.\n",
      "INFO     Collected 0 files for training.\n",
      "INFO     Collected 0 files for validation.\n",
      "INFO     Collected 1 files for test.\n"
     ]
    }
   ],
   "source": [
    "!python mmt/split.py -d midi_Y -v 0 -t 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     Using arguments:\n",
      "{'dataset': 'midi_YX',\n",
      " 'names': PosixPath('data/midi_YX/processed/names.txt'),\n",
      " 'out_dir': PosixPath('data/midi_YX/processed'),\n",
      " 'quiet': False,\n",
      " 'ratio_test': 1.0,\n",
      " 'ratio_valid': 0.0,\n",
      " 'seed': 0}\n",
      "INFO     Loading names...\n",
      "INFO     Loaded 1 names.\n",
      "INFO     Collected 0 files for training.\n",
      "INFO     Collected 0 files for validation.\n",
      "INFO     Collected 1 files for test.\n"
     ]
    }
   ],
   "source": [
    "!python mmt/split.py -d midi_YX -v 0 -t 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate samples and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: python mmt/generate.py -d midi_YX -o exp/midi_YX/ape -g 0 -ns 1\n",
      "Using arguments:\n",
      "{'dataset': 'midi_YX',\n",
      " 'filter': 'top_k',\n",
      " 'filter_threshold': 0.9,\n",
      " 'gpu': 0,\n",
      " 'in_dir': PosixPath('data/midi_YX/processed/notes'),\n",
      " 'jobs': 1,\n",
      " 'model_steps': None,\n",
      " 'n_samples': 1,\n",
      " 'names': PosixPath('data/midi_YX/processed/test-names.txt'),\n",
      " 'out_dir': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_YX/ape'),\n",
      " 'quiet': False,\n",
      " 'seq_len': 1024,\n",
      " 'shuffle': False,\n",
      " 'temperature': 1.0,\n",
      " 'use_csv': False}\n",
      "Saved arguments to /data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_YX/ape/generate-args.json\n",
      "Loading training arguments from: /data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_YX/ape/train-args.json\n",
      "Using loaded arguments:\n",
      "{'abs_pos_emb': True,\n",
      " 'aug': True,\n",
      " 'batch_size': 8,\n",
      " 'dataset': 'sod',\n",
      " 'dim': 512,\n",
      " 'dropout': 0.2,\n",
      " 'early_stopping': True,\n",
      " 'early_stopping_tolerance': 20,\n",
      " 'gpu': 7,\n",
      " 'grad_norm_clip': 1.0,\n",
      " 'heads': 8,\n",
      " 'in_dir': 'data/sod/processed/notes',\n",
      " 'jobs': 8,\n",
      " 'layers': 6,\n",
      " 'learning_rate': 0.0005,\n",
      " 'lr_decay_multiplier': 0.1,\n",
      " 'lr_decay_steps': 100000,\n",
      " 'lr_warmup_steps': 5000,\n",
      " 'max_beat': 256,\n",
      " 'max_seq_len': 1024,\n",
      " 'out_dir': '/data/herman/workspace/mtmt/exp/sod/ape',\n",
      " 'quiet': False,\n",
      " 'rel_pos_emb': False,\n",
      " 'steps': 200000,\n",
      " 'train_names': 'data/sod/processed/train-names.txt',\n",
      " 'use_csv': False,\n",
      " 'valid_names': 'data/sod/processed/valid-names.txt',\n",
      " 'valid_steps': 1000}\n",
      "Using device: cuda:0\n",
      "Creating the data loader...\n",
      "Creating the model...\n",
      "Loaded the model weights from: /data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_YX/ape/checkpoints/best_model.pt\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.02s/it]\n"
     ]
    }
   ],
   "source": [
    "!python mmt/generate.py -d midi_YX -o exp/midi_YX/ape -g 0 -ns 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: python mmt/generate.py -d midi_Y -o exp/midi_Y/ape -g 0 -ns 1\n",
      "Using arguments:\n",
      "{'dataset': 'midi_Y',\n",
      " 'filter': 'top_k',\n",
      " 'filter_threshold': 0.9,\n",
      " 'gpu': 0,\n",
      " 'in_dir': PosixPath('data/midi_Y/processed/notes'),\n",
      " 'jobs': 1,\n",
      " 'model_steps': None,\n",
      " 'n_samples': 1,\n",
      " 'names': PosixPath('data/midi_Y/processed/test-names.txt'),\n",
      " 'out_dir': PosixPath('/data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_Y/ape'),\n",
      " 'quiet': False,\n",
      " 'seq_len': 1024,\n",
      " 'shuffle': False,\n",
      " 'temperature': 1.0,\n",
      " 'use_csv': False}\n",
      "Saved arguments to /data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_Y/ape/generate-args.json\n",
      "Loading training arguments from: /data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_Y/ape/train-args.json\n",
      "Using loaded arguments:\n",
      "{'abs_pos_emb': True,\n",
      " 'aug': True,\n",
      " 'batch_size': 8,\n",
      " 'dataset': 'sod',\n",
      " 'dim': 512,\n",
      " 'dropout': 0.2,\n",
      " 'early_stopping': True,\n",
      " 'early_stopping_tolerance': 20,\n",
      " 'gpu': 7,\n",
      " 'grad_norm_clip': 1.0,\n",
      " 'heads': 8,\n",
      " 'in_dir': 'data/sod/processed/notes',\n",
      " 'jobs': 8,\n",
      " 'layers': 6,\n",
      " 'learning_rate': 0.0005,\n",
      " 'lr_decay_multiplier': 0.1,\n",
      " 'lr_decay_steps': 100000,\n",
      " 'lr_warmup_steps': 5000,\n",
      " 'max_beat': 256,\n",
      " 'max_seq_len': 1024,\n",
      " 'out_dir': '/data/herman/workspace/mtmt/exp/sod/ape',\n",
      " 'quiet': False,\n",
      " 'rel_pos_emb': False,\n",
      " 'steps': 200000,\n",
      " 'train_names': 'data/sod/processed/train-names.txt',\n",
      " 'use_csv': False,\n",
      " 'valid_names': 'data/sod/processed/valid-names.txt',\n",
      " 'valid_steps': 1000}\n",
      "Using device: cuda:0\n",
      "Creating the data loader...\n",
      "Creating the model...\n",
      "Loaded the model weights from: /data2/reach/francis/MMT_experiments/fork/mmt/exp/midi_Y/ape/checkpoints/best_model.pt\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "!python mmt/generate.py -d midi_Y -o exp/midi_Y/ape -g 0 -ns 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute DINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tuple_encoding = {\"type\" : 0,\n",
    "                  \"beat\" : 1, \n",
    "                  \"position\": 2,\n",
    "                  \"pitch\" : 3,\n",
    "                  \"duration\" : 4,\n",
    "                  \"instrument\": 5}\n",
    "\n",
    "def read_logits(folder):\n",
    "    \"\"\"\n",
    "    The logits folder (eg. /exp/midi_data_x/ape/samples/logits/) will have files like:\n",
    "    0_16-beat-continuation-beat_logits.npy\n",
    "    0_16-beat-continuation-duration_logits.npy\n",
    "    0_16-beat-continuation-instrument_logits.npy\n",
    "    0_16-beat-continuation-pitch_logits.npy\n",
    "    0_16-beat-continuation-position_logits.npy\n",
    "    0_16-beat-continuation-type_logits.npy\n",
    "    1_16-beat-continuation-beat_logits.npy\n",
    "    1_16-beat-continuation-duration_logits.npy\n",
    "    1_16-beat-continuation-instrument_logits.npy\n",
    "    1_16-beat-continuation-pitch_logits.npy\n",
    "    1_16-beat-continuation-position_logits.npy\n",
    "    1_16-beat-continuation-type_logits.npy\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n_16-beat-continuation-beat_logits.npy\n",
    "    n_16-beat-continuation-duration_logits.npy\n",
    "    n_16-beat-continuation-instrument_logits.npy\n",
    "    n_16-beat-continuation-pitch_logits.npy\n",
    "    n_16-beat-continuation-position_logits.npy\n",
    "    n_16-beat-continuation-type_logits.npy\n",
    "\n",
    "    This function will read the logits and return a dictionary of the form:\n",
    "    {0 : \n",
    "        {\"type\" : np.array(),\n",
    "        \"beat\" : np.array(),\n",
    "        \"position\" : np.array(),\n",
    "        \"pitch\" : np.array(),\n",
    "        \"duration\" : np.array(),\n",
    "        \"instrument\" : np.array()},\n",
    "    1 :\n",
    "        {\"type\" : np.array(),\n",
    "        \"beat\" : np.array(),\n",
    "        \"position\" : np.array(),\n",
    "        \"pitch\" : np.array(),\n",
    "        \"duration\" : np.array(),\n",
    "        \"instrument\" : np.array()},\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n : \n",
    "        {\"type\" : np.array(),\n",
    "        \"beat\" : np.array(),\n",
    "        \"position\" : np.array(),\n",
    "        \"pitch\" : np.array(),\n",
    "        \"duration\" : np.array(),\n",
    "        \"instrument\" : np.array()}\n",
    "    }\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(folder)\n",
    "    sample_ids = [int(fname.split('_')[0]) for fname in filenames]\n",
    "    logits = {id: dict() for id in sample_ids}\n",
    "\n",
    "    for fname in filenames:\n",
    "        if fname.endswith(\".npy\"):\n",
    "            id = int(fname.split('_')[0])\n",
    "            l_type = fname.split('-')[-1].split('_')[0]\n",
    "            logits[id][l_type] = np.load(os.path.join(folder, fname)).squeeze()\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def read_truth(folder):\n",
    "    \"\"\"\n",
    "    The npy folder (eg. /exp/midi_data_x/ape/samples/npy/) will have files like:\n",
    "    0_truth.npy\n",
    "    1_truth.npy\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n_truth.npy \n",
    "\n",
    "    in addition to the generated files.\n",
    "\n",
    "    This function will read the truth files and return a dictionary of the form:\n",
    "    {0 : np.array(),\n",
    "    1 : np.array(),\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n : np.array()}\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(folder)\n",
    "    \n",
    "    truths = dict()\n",
    "    for fname in filenames:\n",
    "        if fname.endswith(\"_truth.npy\"):\n",
    "            id = int(fname.split('_')[0])\n",
    "            truths[id] = np.load(os.path.join(folder, fname))\n",
    "\n",
    "    return truths\n",
    "\n",
    "def calc_9(logits, truth, add_noise='all'):\n",
    "    \"\"\"\n",
    "    Given logits[i] of the form:\n",
    "\n",
    "    {\"type\" : np.array(),\n",
    "    \"beat\" : np.array(),\n",
    "    \"position\" : np.array(),\n",
    "    \"pitch\" : np.array(),\n",
    "    \"duration\" : np.array(),\n",
    "    \"instrument\" : np.array()}\n",
    "\n",
    "    and truth[i] of the form: np.array(),\n",
    "\n",
    "    this function will compute the entropy each of the 6 positions in the tuple representation:\n",
    "\n",
    "    { \"type\" : entropy,\n",
    "      \"beat\" : entropy,\n",
    "      \"position\" : entropy,\n",
    "      \"pitch\" : entropy,\n",
    "      \"duration\" : entropy,\n",
    "      \"instrument\" : entropy}\n",
    "    \"\"\" \n",
    "\n",
    "    assert add_noise in ['all', 'pitch', 'duration', 'instrument', 'type', 'beat', 'position']\n",
    "\n",
    "    # select notes from truth after the first 16 beats\n",
    "    # selected_truth = truth[truth[:, 1] >= 16]\n",
    "\n",
    "    # select notes from truth after the first 32 elements\n",
    "    selected_truth = truth[32:]\n",
    "\n",
    "    # select rows from logits corresponding to the selected notes\n",
    "    selected_logits = {l_type : logits[l_type][:len(selected_truth)] \n",
    "                       for l_type in logits.keys()}\n",
    "\n",
    "    ######### not converting logits to probabilities #########\n",
    "    probs = {l_type : selected_logits[l_type] for l_type in selected_logits.keys()}\n",
    "\n",
    "    # select the probability of the truth note from probs\n",
    "    selected_probs = {l_type : probs[l_type][np.arange(len(selected_truth)), \n",
    "                                                       selected_truth[:, tuple_encoding[l_type]]]\n",
    "                        for l_type in probs.keys()}\n",
    "\n",
    "    # compute first_term\n",
    "    first_term = {l_type : np.mean(selected_probs[l_type]) for l_type in selected_probs.keys()}\n",
    "\n",
    "    # add noise\n",
    "    noise = {}\n",
    "    if add_noise == 'all':\n",
    "        noise_keys = ['pitch', 'duration', 'beat', 'position']\n",
    "        r = np.random.RandomState(42)\n",
    "        for l_type in noise_keys:\n",
    "            choices = [r.choice(list(set(range(0, probs[l_type].shape[1])).difference(set([selected_truth[i, tuple_encoding[l_type]]])))) \n",
    "                       for i in range(len(selected_truth))]\n",
    "            noise[l_type] = np.array(choices)\n",
    "    else:\n",
    "        noise_keys = [add_noise]\n",
    "        r = np.random.RandomState(42)\n",
    "        choices = [r.choice(list(set(range(0, probs[add_noise].shape[1])).difference(set([selected_truth[i, tuple_encoding[add_noise]]])))) \n",
    "                       for i in range(len(selected_truth))]\n",
    "        noise[add_noise] = np.array(choices)\n",
    "\n",
    "    noisy_probs = selected_probs\n",
    "    for l_type in noise_keys:\n",
    "        noisy_probs[l_type] = probs[l_type][np.arange(len(selected_truth)), noise[l_type]] \n",
    "\n",
    "    # compute second_term\n",
    "    second_term = {l_type : np.log(np.mean(np.exp(noisy_probs[l_type]))) for l_type in noisy_probs.keys()}\n",
    "\n",
    "    # compute 9  \n",
    "    nine = {l_type : first_term[l_type] - second_term[l_type] for l_type in first_term.keys()}\n",
    "\n",
    "    return nine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (124, 6)\n"
     ]
    }
   ],
   "source": [
    "# read ground truth\n",
    "truths = read_truth('exp/midi_Y/ape/samples/npy/')\n",
    "\n",
    "for key in sorted(truths.keys()):\n",
    "    print(key, truths[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "beat (93, 257)\n",
      "duration (93, 33)\n",
      "instrument (93, 65)\n",
      "pitch (93, 129)\n",
      "position (93, 13)\n",
      "type (93, 5)\n"
     ]
    }
   ],
   "source": [
    "# read logits for Y\n",
    "logits = read_logits('exp/midi_Y/ape/samples/logits/')\n",
    "\n",
    "for key in sorted(logits.keys()):\n",
    "    print(key)\n",
    "    for l_type in sorted(logits[key].keys()):\n",
    "        print(l_type, logits[key][l_type].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "beat (171, 257)\n",
      "duration (171, 33)\n",
      "instrument (171, 65)\n",
      "pitch (171, 129)\n",
      "position (171, 13)\n",
      "type (171, 5)\n"
     ]
    }
   ],
   "source": [
    "# read logits for YX\n",
    "logits_YX = read_logits('exp/midi_YX/ape/samples/logits/')\n",
    "\n",
    "for key in sorted(logits_YX.keys()):\n",
    "    print(key)\n",
    "    for l_type in sorted(logits_YX[key].keys()):\n",
    "        print(l_type, logits_YX[key][l_type].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "\n",
      "beat :\n",
      "9b - 9a: -16.91203\n",
      "9a: 9.603898\n",
      "9b: -7.308131\n",
      "\n",
      "duration :\n",
      "9b - 9a: -3.3433762\n",
      "9a: 1.435261\n",
      "9b: -1.9081153\n",
      "\n",
      "pitch :\n",
      "9b - 9a: -2.1911764\n",
      "9a: 3.0902953\n",
      "9b: 0.8991189\n",
      "\n",
      "position :\n",
      "9b - 9a: -6.253174\n",
      "9a: 3.8853662\n",
      "9b: -2.3678079\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# compute DINE\n",
    "for id in sorted(logits.keys()):\n",
    "    print(id, ':')\n",
    "    nine_a = calc_9(logits[id], truths[id])\n",
    "    nine_b = calc_9(logits_YX[id], truths[id])\n",
    "    for key in sorted(['beat', 'position', 'pitch', 'duration']):\n",
    "        print()\n",
    "        print(key, ':')\n",
    "        print('9b - 9a:', nine_b[key] - nine_a[key])\n",
    "        print('9a:', nine_a[key])\n",
    "        print('9b:', nine_b[key])\n",
    "    print('------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
