{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make sure to have completed 'Prerequisites' from README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Copy midi files to `data/{type}/{type_short}/` folder.\n",
    "> Examples: `data/midi_data_x/x/`, `data/midi_data_y/y/`, `data/midi_data_xy/xy/`, `data/midi_data_y_neg/y_neg/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare name list\n",
    "\n",
    "```\n",
    "find data/midi_data_x/x -type f -name *.mid -o -name *.xml | cut -c 20- > data/midi_data_x/original-names.txt\n",
    "```\n",
    "\n",
    "The `cut` command uses 20- here but it depends on the path (`data/midi_data_x/x`) length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert the data to json\n",
    "\n",
    "Make sure the path `data/midi_data_x/processed/json/` exists and run:\n",
    "\n",
    "```\n",
    "python mmt/convert_lmd_full.py -n data/midi_data_x/original-names.txt -i data/midi_data_x/x/ -o data/midi_data_x/processed/json/\n",
    "```\n",
    "\n",
    "### 5. Extract notes\n",
    "\n",
    "Make sure the path `data/midi_data_x/processed/notes/` exists and run:\n",
    "\n",
    "```\n",
    "python mmt/extract.py -d midi_data_x\n",
    "```\n",
    "\n",
    "### 6. Split training/validation/test sets\n",
    "\n",
    "```\n",
    "python mmt/split.py -d midi_data_x -v 0 -t 1\n",
    "```\n",
    "\n",
    "0 and 1 are the validation and test set ratios, respectively. All files are being assigned to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Download pretrained model\n",
    "\n",
    "Download from https://drive.google.com/drive/folders/1HoKfghXOmiqi028oc_Wv0m2IlLdcJglQ?usp=share_link using gdown\n",
    "\n",
    "```\n",
    "gdown --id 1HoKfghXOmiqi028oc_Wv0m2IlLdcJglQ --folder\n",
    "```\n",
    "\n",
    "Copy the `sod-ape` model (best_model.pt) to `exp/midi_data_x/ape/checkpoints/`\n",
    "\n",
    "### 8. Download pre-processed sod dataset\n",
    "\n",
    "Download pre-processed sod dataset (sod_json.zip and sod_notes.zip) from https://drive.google.com/drive/folders/1owWu-Ne8wDoBYCFiF9z11fruJo62m_uK?usp=share_link using gdown\n",
    "\n",
    "```\n",
    "gdown --id 1owWu-Ne8wDoBYCFiF9z11fruJo62m_uK --folder\n",
    "```\n",
    "\n",
    "Extract the files (sod_json.zip and sod_notes.zip) to data/sod/processed/json and data/sod/processed/notes\n",
    "\n",
    "\n",
    "### 9. Start training the sod-ape model to generate the train-args.json file\n",
    "\n",
    "Make sure the folder `exp/sod/ape/checkpoints` exists and then run:\n",
    "\n",
    "```\n",
    "python mmt/train.py -d sod -o exp/sod/ape -g 0\n",
    "```\n",
    "\n",
    "This generates the `train-args.json` file in `exp/sod/ape/`. Copy this file to `exp/midi_data_x/ape/`.\n",
    "\n",
    "### 10. Generate samples using the pre-trained model\n",
    "\n",
    "```\n",
    "python mmt/generate.py -d midi_data_x -o exp/midi_data_x/ape -g 0 -ns 4\n",
    "```\n",
    "\n",
    "### 11. Compute H\n",
    "\n",
    "Using the files in `exp/midi_data_x/ape/samples/logits/` and `exp/midi_data_x/ape/samples/npy/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_encoding = {\"type\" : 0,\n",
    "                  \"beat\" : 1, \n",
    "                  \"position\": 2,\n",
    "                  \"pitch\" : 3,\n",
    "                  \"duration\" : 4,\n",
    "                  \"instrument\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_logits(folder):\n",
    "    \"\"\"\n",
    "    The logits folder (eg. /exp/midi_data_x/ape/samples/logits/) will have files like:\n",
    "    0_16-beat-continuation-beat_logits.npy\n",
    "    0_16-beat-continuation-duration_logits.npy\n",
    "    0_16-beat-continuation-instrument_logits.npy\n",
    "    0_16-beat-continuation-pitch_logits.npy\n",
    "    0_16-beat-continuation-position_logits.npy\n",
    "    0_16-beat-continuation-type_logits.npy\n",
    "    1_16-beat-continuation-beat_logits.npy\n",
    "    1_16-beat-continuation-duration_logits.npy\n",
    "    1_16-beat-continuation-instrument_logits.npy\n",
    "    1_16-beat-continuation-pitch_logits.npy\n",
    "    1_16-beat-continuation-position_logits.npy\n",
    "    1_16-beat-continuation-type_logits.npy\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n_16-beat-continuation-beat_logits.npy\n",
    "    n_16-beat-continuation-duration_logits.npy\n",
    "    n_16-beat-continuation-instrument_logits.npy\n",
    "    n_16-beat-continuation-pitch_logits.npy\n",
    "    n_16-beat-continuation-position_logits.npy\n",
    "    n_16-beat-continuation-type_logits.npy\n",
    "\n",
    "    This function will read the logits and return a dictionary of the form:\n",
    "    {0 : \n",
    "        {\"type\" : np.array(),\n",
    "        \"beat\" : np.array(),\n",
    "        \"position\" : np.array(),\n",
    "        \"pitch\" : np.array(),\n",
    "        \"duration\" : np.array(),\n",
    "        \"instrument\" : np.array()},\n",
    "    1 :\n",
    "        {\"type\" : np.array(),\n",
    "        \"beat\" : np.array(),\n",
    "        \"position\" : np.array(),\n",
    "        \"pitch\" : np.array(),\n",
    "        \"duration\" : np.array(),\n",
    "        \"instrument\" : np.array()},\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n : \n",
    "        {\"type\" : np.array(),\n",
    "        \"beat\" : np.array(),\n",
    "        \"position\" : np.array(),\n",
    "        \"pitch\" : np.array(),\n",
    "        \"duration\" : np.array(),\n",
    "        \"instrument\" : np.array()}\n",
    "    }\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(folder)\n",
    "    sample_ids = [int(fname.split('_')[0]) for fname in filenames]\n",
    "    logits = {id: dict() for id in sample_ids}\n",
    "\n",
    "    for fname in filenames:\n",
    "        if fname.endswith(\".npy\"):\n",
    "            id = int(fname.split('_')[0])\n",
    "            l_type = fname.split('-')[-1].split('_')[0]\n",
    "            logits[id][l_type] = np.load(os.path.join(folder, fname)).squeeze()\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def read_truth(folder):\n",
    "    \"\"\"\n",
    "    The npy folder (eg. /exp/midi_data_x/ape/samples/npy/) will have files like:\n",
    "    0_truth.npy\n",
    "    1_truth.npy\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n_truth.npy \n",
    "\n",
    "    in addition to the generated files.\n",
    "\n",
    "    This function will read the truth files and return a dictionary of the form:\n",
    "    {0 : np.array(),\n",
    "    1 : np.array(),\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n : np.array()}\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(folder)\n",
    "    \n",
    "    truths = dict()\n",
    "    for fname in filenames:\n",
    "        if fname.endswith(\"_truth.npy\"):\n",
    "            id = int(fname.split('_')[0])\n",
    "            truths[id] = np.load(os.path.join(folder, fname))\n",
    "\n",
    "    return truths\n",
    "\n",
    "def calc_entropy(logits, truth):\n",
    "    \"\"\"\n",
    "    Given logits[i] of the form:\n",
    "\n",
    "    {\"type\" : np.array(),\n",
    "    \"beat\" : np.array(),\n",
    "    \"position\" : np.array(),\n",
    "    \"pitch\" : np.array(),\n",
    "    \"duration\" : np.array(),\n",
    "    \"instrument\" : np.array()}\n",
    "\n",
    "    and truth[i] of the form: np.array(),\n",
    "\n",
    "    this function will compute the entropy each of the 6 positions in the tuple representation:\n",
    "\n",
    "    { \"type\" : entropy,\n",
    "      \"beat\" : entropy,\n",
    "      \"position\" : entropy,\n",
    "      \"pitch\" : entropy,\n",
    "      \"duration\" : entropy,\n",
    "      \"instrument\" : entropy}\n",
    "    \"\"\"\n",
    "\n",
    "    # select notes from truth after the first 16 beats\n",
    "    selected_truth = truth[truth[:, 1] >= 16]\n",
    "\n",
    "    # select rows from logits corresponding to the selected notes\n",
    "    selected_logits = {l_type : logits[l_type][:len(selected_truth)] \n",
    "                       for l_type in logits.keys()}\n",
    "\n",
    "    # convert logits to probabilities\n",
    "    probs = {l_type : 1 / (1 + np.exp(-selected_logits[l_type])) for l_type in selected_logits.keys()}\n",
    "\n",
    "    # select the probability of the truth note from probs\n",
    "    selected_probs = {l_type : probs[l_type][np.arange(len(selected_truth)), \n",
    "                                                       selected_truth[:, tuple_encoding[l_type]]]\n",
    "                        for l_type in probs.keys()}\n",
    "\n",
    "    # compute entropy\n",
    "    entropies = {l_type : stats.entropy(selected_probs[l_type], base=2) for l_type in selected_probs.keys()}\n",
    "\n",
    "    return entropies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = read_logits('../exp/midi_data_x/ape/samples/logits/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = read_truth('../exp/midi_data_x/ape/samples/npy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'duration': 6.848968982830749, 'pitch': 7.186772490141254, 'position': 6.567864715856696, 'type': 7.209452874206438, 'beat': 6.812764571032318, 'instrument': 7.209453562137042}\n",
      "\n",
      "1\n",
      "{'beat': 5.906540516424541, 'position': 7.868171880443323, 'type': 7.8703636273459185, 'instrument': 7.8703636273459185, 'pitch': 7.831742515337562, 'duration': 7.866460309101936}\n",
      "\n",
      "2\n",
      "{'duration': 6.320386496779339, 'pitch': 6.518399753746138, 'type': 6.523561984994436, 'instrument': 6.523561297063833, 'position': 5.484863478045357, 'beat': 6.2521788653777515}\n",
      "\n",
      "3\n",
      "{'instrument': 6.67242535206706, 'duration': 6.570473348704983, 'pitch': 6.644028264687195, 'beat': 4.247927448752752, 'position': 5.998470058824936, 'type': 6.672426727928266}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id in logits.keys():\n",
    "    print(id)\n",
    "    print(calc_entropy(logits[id], truths[id]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
